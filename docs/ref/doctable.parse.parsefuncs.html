<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html><head><title>Python: module doctable.parse.parsefuncs</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head><body bgcolor="#f0f0f8">

<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="heading">
<tr bgcolor="#7799ee">
<td valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial">&nbsp;<br><big><big><strong><a href="doctable.html"><font color="#ffffff">doctable</font></a>.<a href="doctable.parse.html"><font color="#ffffff">parse</font></a>.parsefuncs</strong></big></big></font></td
><td align=right valign=bottom
><font color="#ffffff" face="helvetica, arial"><a href=".">index</a><br><a href="file:/net/tts-nas.oit.duke.edu/dc326_research/code/doctable/doctable/parse/parsefuncs.py">/net/tts-nas.oit.duke.edu/dc326_research/code/doctable/doctable/parse/parsefuncs.py</a></font></td></tr></table>
    <p><tt>These&nbsp;functions&nbsp;are&nbsp;used&nbsp;as&nbsp;wrappers&nbsp;around&nbsp;SpaCy&nbsp;parsers,&nbsp;and&nbsp;can&nbsp;be&nbsp;used<br>
either&nbsp;standalone&nbsp;or&nbsp;as&nbsp;part&nbsp;of&nbsp;a&nbsp;doctable.ParsePipeline.<br>
&nbsp;<br>
The&nbsp;two&nbsp;primary&nbsp;parse&nbsp;functions&nbsp;here&nbsp;are&nbsp;`tokenize`&nbsp;and&nbsp;`get_parsetrees`.<br>
Use&nbsp;`tokenize`&nbsp;when&nbsp;you&nbsp;want&nbsp;to&nbsp;extract&nbsp;lists&nbsp;of&nbsp;tokens&nbsp;(split&nbsp;by&nbsp;sentence<br>
or&nbsp;not)&nbsp;and&nbsp;`get_parsetrees`&nbsp;when&nbsp;you'd&nbsp;like&nbsp;to&nbsp;extract&nbsp;condensed&nbsp;versions<br>
of&nbsp;SpaCy&nbsp;parsetrees.<br>
&nbsp;<br>
The&nbsp;`tokenize`&nbsp;function&nbsp;accepts&nbsp;two&nbsp;parameters,&nbsp;`keep_tok_func`&nbsp;and&nbsp;<br>
`parse_tok_func`,&nbsp;which&nbsp;can&nbsp;be&nbsp;custom&nbsp;or&nbsp;optionally&nbsp;filled&nbsp;by&nbsp;<br>
`keep_tok`&nbsp;and&nbsp;`parse_tok`.&nbsp;These&nbsp;methods&nbsp;are&nbsp;also&nbsp;registered&nbsp;as&nbsp;<br>
components&nbsp;in&nbsp;`doctable.ParsePipeline`,&nbsp;so&nbsp;can&nbsp;be&nbsp;accessed&nbsp;using&nbsp;<br>
`doctable.Comp()`&nbsp;as&nbsp;shown&nbsp;below.<br>
&nbsp;<br>
```<br>
#&nbsp;add&nbsp;pipeline&nbsp;components<br>
parser&nbsp;=&nbsp;doctable.ParsePipeline([<br>
&nbsp;&nbsp;&nbsp;&nbsp;spacy.load('en'),&nbsp;#&nbsp;first&nbsp;run&nbsp;spacy&nbsp;parser<br>
&nbsp;&nbsp;&nbsp;&nbsp;doctable.Comp('tokenize',&nbsp;**{<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'split_sents':&nbsp;False,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'keep_tok_func':&nbsp;doctable.Comp('keep_tok'),<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'parse_tok_func':&nbsp;doctable.Comp('parse_tok'),<br>
&nbsp;&nbsp;&nbsp;&nbsp;})<br>
])<br>
```<br>
&nbsp;<br>
A&nbsp;more&nbsp;complete&nbsp;`ParsePipeline`&nbsp;example&nbsp;might&nbsp;look&nbsp;like&nbsp;the&nbsp;code&nbsp;below.<br>
This&nbsp;example&nbsp;uses&nbsp;the&nbsp;`merge_tok_spans`&nbsp;function&nbsp;to&nbsp;merge&nbsp;named&nbsp;entities&nbsp;as<br>
single&nbsp;tokens&nbsp;in&nbsp;SpaCy&nbsp;then&nbsp;uses&nbsp;the&nbsp;`tokenize`&nbsp;function&nbsp;in&nbsp;conjunction&nbsp;<br>
with&nbsp;`keep_tok`&nbsp;(which&nbsp;drops&nbsp;whitespace&nbsp;tokens&nbsp;but&nbsp;keeps&nbsp;punctuation&nbsp;and&nbsp;<br>
stopwords)&nbsp;and&nbsp;`parse_tok`&nbsp;(which&nbsp;capitalizes&nbsp;named&nbsp;entities,&nbsp;replaces&nbsp;<br>
numbers&nbsp;with&nbsp;"NUM",&nbsp;and&nbsp;does&nbsp;not&nbsp;lemmatize&nbsp;tokens).<br>
&nbsp;<br>
```<br>
parser&nbsp;=&nbsp;doctable.ParsePipeline([<br>
&nbsp;&nbsp;&nbsp;&nbsp;spacy.load('en'),&nbsp;#&nbsp;spacy&nbsp;nlp&nbsp;parser&nbsp;object<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;merge&nbsp;spacy&nbsp;multi-word&nbsp;named&nbsp;entities&nbsp;(doctable.parse.merge_tok_spans)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Comp('merge_tok_spans',&nbsp;merge_ents=True,&nbsp;merge_noun_chunks=False),<br>
&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;tokenize&nbsp;document<br>
&nbsp;&nbsp;&nbsp;&nbsp;Comp('tokenize',&nbsp;**{<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'split_sents':&nbsp;False,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;choose&nbsp;tokens&nbsp;to&nbsp;keep&nbsp;(doctable.parse.keep_tok)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'keep_tok_func':&nbsp;Comp('keep_tok',&nbsp;**{<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'keep_whitespace':&nbsp;False,&nbsp;#&nbsp;don't&nbsp;keep&nbsp;whitespace<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'keep_punct':&nbsp;True,&nbsp;#&nbsp;keep&nbsp;punctuation&nbsp;and&nbsp;stopwords<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'keep_stop':&nbsp;True,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}),<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;choose&nbsp;how&nbsp;to&nbsp;convert&nbsp;Spacy&nbsp;token&nbsp;t&nbsp;text&nbsp;(doctable.parse.parse_tok)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'parse_tok_func':&nbsp;Comp('parse_tok',&nbsp;**{<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'format_ents':&nbsp;True,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'lemmatize':&nbsp;False,<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'num_replacement':&nbsp;'NUM',<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'ent_convert':&nbsp;lambda&nbsp;e:&nbsp;e.text.upper(),&nbsp;#&nbsp;function&nbsp;to&nbsp;capitalize&nbsp;named&nbsp;entities<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;})<br>
&nbsp;&nbsp;&nbsp;&nbsp;})<br>
])<br>
```</tt></p>
<p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#aa55cc">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Modules</strong></big></font></td></tr>
    
<tr><td bgcolor="#aa55cc"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><table width="100%" summary="list"><tr><td width="25%" valign=top><a href="re.html">re</a><br>
</td><td width="25%" valign=top></td><td width="25%" valign=top></td><td width="25%" valign=top></td></tr></table></td></tr></table><p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#eeaa77">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Functions</strong></big></font></td></tr>
    
<tr><td bgcolor="#eeaa77"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><dl><dt><a name="-get_parsetrees"><strong>get_parsetrees</strong></a>(doc, text_parse_func=None, info_func_map={})</dt><dd><tt>Extracts&nbsp;parsetree&nbsp;from&nbsp;spacy&nbsp;doc&nbsp;objects.<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;doc&nbsp;(spacy.Doc&nbsp;object):&nbsp;doc&nbsp;to&nbsp;generate&nbsp;parsetree&nbsp;from.<br>
&nbsp;&nbsp;&nbsp;&nbsp;parse_tok_func&nbsp;(func):&nbsp;function&nbsp;used&nbsp;to&nbsp;convert&nbsp;token&nbsp;to&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;string&nbsp;representation.&nbsp;Usually&nbsp;a&nbsp;lambda&nbsp;function&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;wrapping&nbsp;some&nbsp;variant&nbsp;of&nbsp;self.parse_tok().<br>
&nbsp;&nbsp;&nbsp;&nbsp;info_func_map&nbsp;(dict&lt;str-&gt;func&gt;):&nbsp;attribute&nbsp;to&nbsp;function&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mapping.&nbsp;Functions&nbsp;take&nbsp;a&nbsp;token&nbsp;and&nbsp;output&nbsp;a&nbsp;property<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;that&nbsp;will&nbsp;be&nbsp;stored&nbsp;in&nbsp;each&nbsp;parsetree&nbsp;node.</tt></dd></dl>
 <dl><dt><a name="-identity"><strong>identity</strong></a>(x)</dt></dl>
 <dl><dt><a name="-keep_tok"><strong>keep_tok</strong></a>(tok, keep_whitespace=False, keep_punct=True, keep_stop=True, keep_digit=True, keep_num=True, keep_ents=True, keep_ent_types=None, rm_ent_types=None, keep_pos=None, rm_pos=None, addtnl_func=None)</dt><dd><tt>Decide&nbsp;to&nbsp;use&nbsp;token&nbsp;or&nbsp;not&nbsp;(can&nbsp;be&nbsp;overridden).<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;keep_whitespace&nbsp;(bool):&nbsp;keep&nbsp;all-whitespace&nbsp;tokens.<br>
&nbsp;&nbsp;&nbsp;&nbsp;keep_punct&nbsp;(bool):&nbsp;keep&nbsp;punctuation.<br>
&nbsp;&nbsp;&nbsp;&nbsp;keep_stop&nbsp;(bool):&nbsp;keep&nbsp;stopwords.<br>
&nbsp;&nbsp;&nbsp;&nbsp;keep_num&nbsp;(bool):&nbsp;keep&nbsp;numbers&nbsp;using&nbsp;tok.is_num.<br>
&nbsp;&nbsp;&nbsp;&nbsp;keep_digit&nbsp;(bool):&nbsp;keep&nbsp;digits&nbsp;using&nbsp;tok.is_digit.<br>
&nbsp;&nbsp;&nbsp;&nbsp;keep_ents&nbsp;(bool):&nbsp;keep&nbsp;named&nbsp;entities<br>
&nbsp;&nbsp;&nbsp;&nbsp;keep_ent_types&nbsp;(list&lt;str&gt;):&nbsp;keep&nbsp;only&nbsp;these&nbsp;entity&nbsp;types<br>
&nbsp;&nbsp;&nbsp;&nbsp;rm_ent_types&nbsp;(list&lt;str&gt;):&nbsp;remove&nbsp;these&nbsp;entity&nbsp;types<br>
&nbsp;&nbsp;&nbsp;&nbsp;keep_pos&nbsp;(list&lt;str&gt;):&nbsp;keep&nbsp;only&nbsp;toks&nbsp;with&nbsp;these&nbsp;POS<br>
&nbsp;&nbsp;&nbsp;&nbsp;rm_pos&nbsp;(list&lt;str&gt;):&nbsp;remove&nbsp;toks&nbsp;with&nbsp;these&nbsp;POS<br>
&nbsp;&nbsp;&nbsp;&nbsp;addtnl_func&nbsp;(func):&nbsp;additional&nbsp;custom&nbsp;criteria&nbsp;to&nbsp;meet<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;True&nbsp;if&nbsp;token&nbsp;should&nbsp;be&nbsp;kept.</tt></dd></dl>
 <dl><dt><a name="-merge_tok_ngrams"><strong>merge_tok_ngrams</strong></a>(toks, ngrams=(), ngram_sep='_')</dt><dd><tt>Merges&nbsp;manually&nbsp;specified&nbsp;consecutive&nbsp;tokens&nbsp;into&nbsp;single&nbsp;tokens.<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;toks&nbsp;(list&lt;str&gt;):&nbsp;token&nbsp;list&nbsp;through&nbsp;which&nbsp;to&nbsp;search&nbsp;for&nbsp;ngrams.<br>
&nbsp;&nbsp;&nbsp;&nbsp;ngrams&nbsp;(list&lt;list&lt;str&gt;&gt;):&nbsp;list&nbsp;of&nbsp;ngrams&nbsp;(as&nbsp;sequence&nbsp;of&nbsp;str)&nbsp;to&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;combine&nbsp;into&nbsp;single&nbsp;tokens.<br>
&nbsp;&nbsp;&nbsp;&nbsp;ngram_sep&nbsp;(str):&nbsp;string&nbsp;to&nbsp;join&nbsp;ngram&nbsp;parts&nbsp;with.</tt></dd></dl>
 <dl><dt><a name="-merge_tok_spans"><strong>merge_tok_spans</strong></a>(doc, merge_ents=True, spacy_ngram_matcher=None, merge_noun_chunks=False)</dt><dd><tt>Apply&nbsp;merges&nbsp;to&nbsp;doc&nbsp;object&nbsp;including&nbsp;entities,&nbsp;normal&nbsp;ngrams,&nbsp;and&nbsp;noun&nbsp;chunks.<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;doc&nbsp;(Spacy&nbsp;Doc&nbsp;object):&nbsp;doc&nbsp;to&nbsp;merge&nbsp;spans&nbsp;in<br>
&nbsp;&nbsp;&nbsp;&nbsp;merge_ents&nbsp;(bool):&nbsp;combine&nbsp;multi-word&nbsp;entities&nbsp;using&nbsp;spacy&nbsp;doc.retokenize()<br>
&nbsp;&nbsp;&nbsp;&nbsp;spacy_ngram_matcher&nbsp;(spacy&nbsp;Matcher&nbsp;object):&nbsp;rule-based&nbsp;matching&nbsp;object&nbsp;for&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ngrams&nbsp;in&nbsp;Spacy.&nbsp;See&nbsp;https://spacy.io/usage/rule-based-matching<br>
&nbsp;&nbsp;&nbsp;&nbsp;merge_noun_chunks&nbsp;(bool):&nbsp;automatically&nbsp;merge&nbsp;noun&nbsp;chunks</tt></dd></dl>
 <dl><dt><a name="-parse_tok"><strong>parse_tok</strong></a>(tok, num_replacement=None, digit_replacement=None, lemmatize=False, normal_tok_parse=None, format_ents=False, ent_convert=None)</dt><dd><tt>Convert&nbsp;spacy&nbsp;token&nbsp;object&nbsp;to&nbsp;string.<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tok&nbsp;(spacy&nbsp;token&nbsp;or&nbsp;span):&nbsp;token&nbsp;object&nbsp;to&nbsp;convert&nbsp;to&nbsp;string.<br>
&nbsp;&nbsp;&nbsp;&nbsp;replace_num&nbsp;(str/None):&nbsp;Replace&nbsp;number&nbsp;following&nbsp;tok.like_num&nbsp;(includes&nbsp;"five",&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;or&nbsp;5)&nbsp;with&nbsp;a&nbsp;special&nbsp;token&nbsp;(i.e.&nbsp;__NUM__).&nbsp;None&nbsp;means&nbsp;no&nbsp;replacement.<br>
&nbsp;&nbsp;&nbsp;&nbsp;replace_digit&nbsp;(str/None):&nbsp;Replace&nbsp;digit&nbsp;meeting&nbsp;tok.is_digit&nbsp;with&nbsp;special&nbsp;token.&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Only&nbsp;used&nbsp;when&nbsp;replace_num&nbsp;is&nbsp;None.<br>
&nbsp;&nbsp;&nbsp;&nbsp;lemmatize&nbsp;(bool):&nbsp;return&nbsp;lemma&nbsp;instead&nbsp;of&nbsp;full&nbsp;word.<br>
&nbsp;&nbsp;&nbsp;&nbsp;normal_convert&nbsp;(func):&nbsp;custom&nbsp;conversion&nbsp;function&nbsp;to&nbsp;happen&nbsp;as&nbsp;last&nbsp;step<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;non-entities.&nbsp;This&nbsp;way&nbsp;can&nbsp;keep&nbsp;all&nbsp;other&nbsp;functionality.<br>
&nbsp;&nbsp;&nbsp;&nbsp;format_ents&nbsp;(bool):&nbsp;Replace&nbsp;whitespace&nbsp;with&nbsp;space&nbsp;and&nbsp;capitalize&nbsp;first&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;letter&nbsp;of&nbsp;ents.<br>
&nbsp;&nbsp;&nbsp;&nbsp;ent_convert&nbsp;(func):&nbsp;custom&nbsp;conversion&nbsp;function&nbsp;to&nbsp;happen&nbsp;as&nbsp;last&nbsp;step<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;entities.&nbsp;This&nbsp;way&nbsp;can&nbsp;keep&nbsp;all&nbsp;other&nbsp;functionality.</tt></dd></dl>
 <dl><dt><a name="-preprocess"><strong>preprocess</strong></a>(text, replace_url=None, replace_xml=None, replace_digits=None)</dt><dd><tt>A&nbsp;few&nbsp;useful&nbsp;preprocessing&nbsp;functions&nbsp;for&nbsp;raw&nbsp;text.<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;text&nbsp;(str):&nbsp;document&nbsp;as&nbsp;a&nbsp;text&nbsp;string<br>
&nbsp;&nbsp;&nbsp;&nbsp;replace_url&nbsp;(str&nbsp;or&nbsp;None):&nbsp;if&nbsp;not&nbsp;None,&nbsp;replace&nbsp;url&nbsp;with&nbsp;string<br>
&nbsp;&nbsp;&nbsp;&nbsp;replace_xml&nbsp;(str&nbsp;or&nbsp;None):&nbsp;if&nbsp;not&nbsp;None,&nbsp;replace&nbsp;xml&nbsp;tags&nbsp;with&nbsp;string<br>
&nbsp;&nbsp;&nbsp;&nbsp;replace_digits&nbsp;(str&nbsp;or&nbsp;None):&nbsp;if&nbsp;not&nbsp;None,&nbsp;replace&nbsp;digits&nbsp;with&nbsp;string</tt></dd></dl>
 <dl><dt><a name="-tokenize"><strong>tokenize</strong></a>(doc, split_sents=True, keep_tok_func=None, parse_tok_func=None)</dt><dd><tt>Convert&nbsp;spacy&nbsp;doc&nbsp;into&nbsp;a&nbsp;series&nbsp;of&nbsp;tokens&nbsp;(as&nbsp;sentences&nbsp;or&nbsp;not).<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;split_sents&nbsp;(bool):&nbsp;parse&nbsp;into&nbsp;list&nbsp;of&nbsp;sentence&nbsp;tokens&nbsp;using&nbsp;doc.sents.<br>
&nbsp;&nbsp;&nbsp;&nbsp;merge_ents&nbsp;(bool):&nbsp;merge&nbsp;multi_word&nbsp;entities&nbsp;into&nbsp;same&nbsp;token.<br>
&nbsp;&nbsp;&nbsp;&nbsp;ngrams&nbsp;(iter&lt;iter&lt;str&gt;&gt;):&nbsp;iterable&nbsp;of&nbsp;token&nbsp;tuples&nbsp;to&nbsp;merge&nbsp;after&nbsp;parsing.<br>
&nbsp;&nbsp;&nbsp;&nbsp;spacy_ngram_matcher&nbsp;(spacy&nbsp;Matcher):&nbsp;matcher&nbsp;object&nbsp;to&nbsp;use&nbsp;on&nbsp;the&nbsp;spacy&nbsp;doc.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Normally&nbsp;will&nbsp;create&nbsp;using&nbsp;spacy.Matcher(nlp.vocab),&nbsp;see&nbsp;more&nbsp;details<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;at&nbsp;https://spacy.io/usage/rule-based-matching&nbsp;And&nbsp;also&nbsp;note&nbsp;that&nbsp;the&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;nlp&nbsp;object&nbsp;must&nbsp;be&nbsp;the&nbsp;one&nbsp;used&nbsp;for&nbsp;parsing.<br>
&nbsp;&nbsp;&nbsp;&nbsp;keep_tok_func&nbsp;(func):&nbsp;func&nbsp;used&nbsp;to&nbsp;decide&nbsp;to&nbsp;keep&nbsp;func&nbsp;or&nbsp;not.&nbsp;Default&nbsp;is<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;identity&nbsp;function<br>
&nbsp;&nbsp;&nbsp;&nbsp;parse_tok_func&nbsp;(func):&nbsp;func&nbsp;used&nbsp;to&nbsp;parse&nbsp;tokens.&nbsp;By&nbsp;default&nbsp;uses&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;identify&nbsp;function.</tt></dd></dl>
</td></tr></table><p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#55aa55">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Data</strong></big></font></td></tr>
    
<tr><td bgcolor="#55aa55"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><strong>re_digits</strong> = re.compile('\\d*[-\\./,]*\\d+')<br>
<strong>re_url</strong> = re.compile('http\\S+', re.MULTILINE)<br>
<strong>re_xml_tag</strong> = re.compile('&lt;[^&lt;]+&gt;', re.MULTILINE)</td></tr></table>
</body></html>