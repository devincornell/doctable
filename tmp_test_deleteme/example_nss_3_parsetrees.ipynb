{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Vignette 3: Storing Parsed Documents\n",
    "\n",
    "Here I'll show how to make a DocTable for storing NSS documents at the paragraph level, and parse the documents in parallel.\n",
    "\n",
    "For context, check out [Example 1](https://devincornell.github.io/doctable/examples/ex_nss.html) - here we'll just use some shortcuts for code used there. These come from the util.py code in the repo examples folder.\n",
    "\n",
    "These are the vignettes I have created:\n",
    "\n",
    "+ [1: Storing Document Metadata](example_nss_1_intro.html)\n",
    "\n",
    "+ [2: Storing Document Text](example_nss_2_parsing.html)\n",
    "\n",
    "+ [3: Storing Parsed Documents](example_nss_3_parsetrees.html)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "#import util\n",
    "import doctable\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# automatically clean up temp folder after python ends\n",
    "tmpfolder = doctable.TempFolder('tmp')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we define the metadata and download the text data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import urllib\n",
    "def download_nss(year):\n",
    "    ''' Simple helper function for downloading texts from my nssdocs repo.'''\n",
    "    baseurl = 'https://raw.githubusercontent.com/devincornell/nssdocs/master/docs/{}.txt'\n",
    "    url = baseurl.format(year)\n",
    "    text = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "    return text\n",
    "\n",
    "document_metadata = [\n",
    "    {'year': 2000, 'party': 'D', 'president': 'Clinton'},\n",
    "    {'year': 2006, 'party': 'R', 'president': 'W. Bush'}, \n",
    "    {'year': 2015, 'party': 'D', 'president': 'Obama'}, \n",
    "    {'year': 2017, 'party': 'R', 'president': 'Trump'}, \n",
    "]\n",
    "\n",
    "sep = '\\n\\n'\n",
    "first_n = 10\n",
    "for md in document_metadata:\n",
    "    text = download_nss(md['year'])\n",
    "    md['text'] = sep.join(text.split(sep)[:first_n])\n",
    "print(f\"{len(document_metadata[0]['text'])=}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "len(document_metadata[0]['text'])=6695\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Define the DocTable Schema\n",
    "Now we define a doctable schema using the `doctable.schema` class decorator and the [pickle file column type](examples/doctable_file_column_types.html) to prepare to store parsetrees as binary data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# to be used as a database row representing a single NSS document\n",
    "@doctable.schema\n",
    "class NSSDoc:\n",
    "    __slots__ = [] # include so that doctable.schema can create a slot class\n",
    "    \n",
    "    id: int = doctable.IDCol() # this is an alias for doctable.Col(primary_key=True, autoincrement=True)\n",
    "    year: int =  doctable.Col()\n",
    "    party: str = doctable.Col()\n",
    "    president: str = doctable.Col()\n",
    "    text: str = doctable.Col()\n",
    "    doc: doctable.ParseTreeDoc = doctable.ParseTreeFileCol('tmp/parsetree_pickle_files')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "doctable.ParseTreeFileCol('tmp/parsetree_pickle_files')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Field(name=None,type=None,default=EmptyValue(),default_factory=<dataclasses._MISSING_TYPE object at 0x7fe5edc8f6d0>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({'column_metadata': ColumnMetadata(column_type=None, type_kwargs={}, column_kwargs={'coltype': 'parsetree', 'type_args': {'folder': 'tmp/parsetree_pickle_files'}})}),_field_type=None)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "And a class to represent an NSS DocTable."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class NSSDocTable(doctable.DocTable):\n",
    "    _tabname_ = 'nss_documents'\n",
    "    _schema_ = NSSDoc\n",
    "    \n",
    "nss_table = NSSDocTable(target='tmp/nss_3.db', new_db=True)\n",
    "nss_table.count()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "\"folder\" must be provided when initializing a file type.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e535bb744984>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0m_schema_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNSSDoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnss_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNSSDocTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tmp/nss_3.db'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_db\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mnss_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/doctable/doctable/doctable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, tabname, schema, indices, constraints, dialect, engine, readonly, new_db, new_table, persistent_conn, verbose, **engine_kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDocTableSchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A dataclass schema must inherit from doctable.DocTableSchema.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_schema_dataclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constraints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_schema_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tabname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/doctable/doctable/schemas/parse_schema_dataclass.py\u001b[0m in \u001b[0;36mparse_schema_dataclass\u001b[0;34m(Cls, indices, constraints)\u001b[0m\n\u001b[1;32m     11\u001b[0m     ''' Convert a dataclass definition to a list of sqlalchemy columns.\n\u001b[1;32m     12\u001b[0m     '''\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparse_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparse_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparse_constraints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/doctable/doctable/schemas/parse_schema_dataclass.py\u001b[0m in \u001b[0;36mparse_columns\u001b[0;34m(Cls)\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;31m# if column metadata was provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumnMetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                     \u001b[0muse_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sqlalchemy_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                     \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlalchemy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/doctable/doctable/schemas/parse_schema_dataclass.py\u001b[0m in \u001b[0;36mget_sqlalchemy_type\u001b[0;34m(self, type_hint)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# has no column type information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mpython_to_slqlchemy_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_hint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqlalchemy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickleType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# is a string for a type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/doctable/doctable/schemas/custom_coltypes.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, folder, *arg, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mfname_num_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileTypeControl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTypeDecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/doctable/doctable/schemas/custom_coltypes.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, folder)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\"folder\" must be provided when initializing a file type.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: \"folder\" must be provided when initializing a file type."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for md in document_metadata:\n",
    "    nss_table.insert(md)\n",
    "nss_table.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Create a Parser Class Using a Pipeline\n",
    "Now we create a small `NSSParser` class that keeps a `doctable.ParsePipeline` object for doing the actual text processing. As you can see from our init method, instantiating the package will load a spacy module into memory and construct the pipeline from the selected components. We also create a wrapper over the pipeline `.parse` and `.parsemany` methods. Here we define, instantiate, and view the components of `NSSParser`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class NSSParser:\n",
    "    ''' Handles text parsing for NSS documents.'''\n",
    "    def __init__(self):\n",
    "        nlp = spacy.load('en_core_web_sm')\n",
    "        \n",
    "        # this determines all settings for tokenizing\n",
    "        self.pipeline = doctable.ParsePipeline([\n",
    "            nlp, # first run spacy parser\n",
    "            doctable.Comp('merge_tok_spans', merge_ents=True),\n",
    "            doctable.Comp('get_parsetrees', **{\n",
    "                'text_parse_func': doctable.Comp('parse_tok', **{\n",
    "                    'format_ents': True,\n",
    "                    'num_replacement': 'NUM',\n",
    "                })\n",
    "            })\n",
    "        ])\n",
    "    \n",
    "    def parse(self, text):\n",
    "        return self.pipeline.parse(text)\n",
    "\n",
    "parser = NSSParser() # creates a parser instance\n",
    "parser.pipeline.components"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we parse the paragraphs of each document in parallel."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for doc in tqdm(nss_table.select(['id','year','text'])):\n",
    "    parsed = parser.parse(doc.text)\n",
    "    nss_table.update({'doc': parsed}, where=nss_table['id']==doc.id)\n",
    "nss_table.select_df(limit=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Work With Parsetrees\n",
    "\n",
    "Now that we have stored our parsed text as files in the database, we can manipulate the parsetrees. This example shows the 5 most common nouns from each national security strategy document. This is possible because the `doctable.ParseTree` data structures contain `pos` information originally provided by the spacy parser. Using `ParseTreeFileType` allows us to more efficiently store pickled binary data so that we can perform these kinds of analyses at scale."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from collections import Counter # used to count tokens\n",
    "\n",
    "for nss in nss_table.select():\n",
    "    noun_counts = Counter([tok.text for pt in nss.doc for tok in pt if tok.pos == 'NOUN'])\n",
    "    print(f\"{nss.president} ({nss.year}): {noun_counts.most_common(5)}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definitely check out this [example on parsetreedocs](examples/doctable_parsetreedoc_column.html) if you're interested in more applications.\n",
    "\n",
    "And that is all for this vignette! See the list of vignettes at the top of this page for more examples."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "80712910726593b564a07c7ac6087ce3072c1b43af7fa58c28aea85a2c346dd3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}