{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrency\n",
    "Databases are able to handle concurrency easily. The best way to use concurrent connections is to set the timeout parameter passed to the sqlalchemy.engine function as an extra argument to the constructure (captured by `**engine_args`). Note that while the ``persistent_conn`` constructor argument may have other uses, it does not have much of an effect on concurrent operations in this version of DocTable2.\n",
    "\n",
    "Here I'll set up a simple test case for concurrent operations, where I run two threads simultaneously inserting many large data rows. We will see that when timeouts are set to be large, the threads take turns in inserting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "from multiprocessing import Process\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import doctable as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define database schema to be sent to processes\n",
    "fname = 'tmp_connections2.db'\n",
    "schema = (\n",
    "    ('id', 'integer', dict(primary_key=True, autoincrement=True)),\n",
    "    ('data','pickle'),\n",
    "    ('procname','string')\n",
    ")\n",
    "big_data = [i for i in range(10000000)] # create big data object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a thread that takes a schema and inserts three big rows\n",
    "def thread_writer(timeout, schema, fname, data, procname):\n",
    "    db = dt.DocTable2(schema, persistent_conn=True, fname=fname, connect_args={'timeout': timeout})\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            db.insert({'data':data,'procname':procname})\n",
    "        except sqlalchemy.exc.OperationalError:\n",
    "            print('Raised the \"(sqlite3.OperationalError) database is locked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to run the processes defined by thread_writer\n",
    "def run_processes(timeout_sec, schema, fname, big_data):\n",
    "    \n",
    "    if os.path.exists(fname):\n",
    "        os.remove(fname)\n",
    "    \n",
    "    baseargs = (timeout_sec,schema,fname,big_data)\n",
    "    p1 = Process(target=thread_writer, args=(*baseargs,'p1'))\n",
    "    p2 = Process(target=thread_writer, args=(*baseargs,'p2'))\n",
    "    \n",
    "    p1.start(), p2.start() # start the processes\n",
    "    p1.join(), p2.join() # wait for processes to finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct Example\n",
    "First we show a correctly working version with a sufficiently large timeout. Each thread will attempt to insert three large pickled objects (big lists) into the database. Because the timeout is sufficiently long, the processes will take turns in inserting data. You can see that effect by looking at the select statement below. The two threads have two different names that they inserted in the database, \"p1\" and \"p2\". The rows alternate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeout = 10 # seconds\n",
    "run_processes(timeout, schema, fname, big_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DocTable2::_documents_ ct: 6>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 'p1'), (2, 'p2'), (3, 'p1'), (4, 'p2'), (5, 'p1'), (6, 'p2')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = dt.DocTable2(fname=fname)\n",
    "print(db)\n",
    "db.select(['id','procname'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failure Example\n",
    "We can induce a failure case by setting the timeout to 0. Because the threads are inserting large python objects, one thread does not finish writing before the other attempts to write. When the insertion fails, it will give the python exception `sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) database is locked`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raised the \"(sqlite3.OperationalError) database is locked\n"
     ]
    }
   ],
   "source": [
    "timeout = 0 # seconds\n",
    "run_processes(timeout, schema, fname, big_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the exception was caught, the threads continued to run. The results of an error means it will simply skip the given insert, but the behavior is in general undefined in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DocTable2::_documents_ ct: 5>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 'p1'), (2, 'p2'), (3, 'p1'), (4, 'p2'), (5, 'p1')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = dt.DocTable2(fname=fname)\n",
    "print(db)\n",
    "db.select(['id','procname'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
