{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doctable Demo: US National Security Strategy Documents\n",
    "In this example, I'll show how to create a database for document + metadata storage using the `DocTable` class, and a parser class using `DocParser`. We will store the metadata you see below in addition to the formatted document text.\n",
    "\n",
    "This example shows a full example of a doctable workflow designed to parse texts end-to-end, using the NSS documents for demonstation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import doctable\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "from pprint import pprint\n",
    "import urllib.request # used for downloading nss docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Dataset\n",
    "This dataset is the plain text version of the US National Security Strategy documents. During the parsing process, all plain text files will be downloaded from my [github project hosting the nss docs](https://github.com/devincornell/nssdocs). I compiled the metadata you see below from [a page hosted by the historical dept of the secretary's office](https://history.defense.gov/Historical-Sources/National-Security-Strategy/). In short, each US President must release at least one NSS per term, with some (namely Clinton) producing more.\n",
    "\n",
    "Here I've created the function `download_nss` to download the text data from my nssdocs github repository, and the python dictionary `nss_metadata` to store information about each document to be stored in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_nss(year):\n",
    "    ''' Simple helper function for downloading texts from my nssdocs repo.'''\n",
    "    baseurl = 'https://raw.githubusercontent.com/devincornell/nssdocs/master/docs/{}.txt'\n",
    "    url = baseurl.format(year)\n",
    "    text = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nss_metadata = {\n",
    "            1987: {'party': 'R', 'president': 'Reagan'}, \n",
    "            1993: {'party': 'R', 'president': 'H.W. Bush'}, \n",
    "            2002: {'party': 'R', 'president': 'W. Bush'}, \n",
    "            2015: {'party': 'D', 'president': 'Obama'}, \n",
    "            1994: {'party': 'D', 'president': 'Clinton'}, \n",
    "            1990: {'party': 'R', 'president': 'H.W. Bush'}, \n",
    "            1991: {'party': 'R', 'president': 'H.W. Bush'}, \n",
    "            2006: {'party': 'R', 'president': 'W. Bush'}, \n",
    "            1997: {'party': 'D', 'president': 'Clinton'}, \n",
    "            1995: {'party': 'D', 'president': 'Clinton'}, \n",
    "            1988: {'party': 'R', 'president': 'Reagan'}, \n",
    "            2017: {'party': 'R', 'president': 'Trump'}, \n",
    "            1996: {'party': 'D', 'president': 'Clinton'}, \n",
    "            2010: {'party': 'D', 'president': 'Obama'}, \n",
    "            1999: {'party': 'D', 'president': 'Clinton'}, \n",
    "            1998: {'party': 'D', 'president': 'Clinton'}, \n",
    "            2000: {'party': 'D', 'president': 'Clinton'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Preface \\n\\nAmerican Leadership for Peaceful Change \\n\\nOur great Nation stands at a crossroads in histo'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloader example: first 100 characters of 1993 NSS document\n",
    "text = download_nss(1993)\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DocTable and Parsing for NSS Document Dataset\n",
    "This class inherits from DocTable and will typically store schema and other static inforamtion about the database. This is the most common way to work with DocTable. You can see we keep two class member variables to store the database table name and the schema. See the [schema guide](examples/doctable_schema.html) for more schema examples.\n",
    "\n",
    "We also create a `.insert_nssdoc()` method which wraps the `DocTable.insert()` method to make insertion easier by counting paragraphs, sentences, and tokens to insert. A `.print_doctable()` static method is created so we can print the contents of a NSSDocs database later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NSSDocs(doctable.DocTable):\n",
    "    tabname = 'nssdocs'\n",
    "    schema = (\n",
    "        ('idcol', 'id'), # doctable shortcut for automatic index\n",
    "        \n",
    "        # some metdata about the documents\n",
    "        ('integer', 'year', dict(unique=True, nullable=False)),\n",
    "        ('string','president'),\n",
    "        ('string','party'), ('check_constraint', 'party in (\"R\",\"D\")'),\n",
    "        \n",
    "        # raw and parsed text data\n",
    "        ('string', 'text'),\n",
    "        ('pickle','parsed'), # nested tokens within each paragraph\n",
    "        \n",
    "        # metdata\n",
    "        ('integer','num_paragraphs'),\n",
    "        ('integer', 'num_tokens'),\n",
    "        \n",
    "        # indices for easy access\n",
    "        ('index', 'ind_yr', ['year'], dict(unique=True)),\n",
    "    )\n",
    "    def __init__(self, fname=':memory:', **kwargs):\n",
    "        super().__init__(fname=fname, schema=self.schema, tabname=self.tabname, **kwargs)\n",
    "        \n",
    "        \n",
    "    def update(self, row, **kwargs):\n",
    "        ''' Override insert to automatically calculate num_paragraphs and num_tokens.\n",
    "        '''\n",
    "        if 'parsed' in row:\n",
    "            row['num_paragraphs'] = len(row['parsed'])\n",
    "            row['num_tokens'] = len([tok for par in row['parsed'] for tok in par])\n",
    "        \n",
    "        return super().update(row, **kwargs) # call the regular doctable insert now.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then create a connection to a database by instantiating. Since the fname parameter was not provided, this doctable exists only in memory using sqlite (uses special sqlite name \":memory:\"). Our other examples will use files, but instantiating in memory first is a good way to check that the schema is valid. We can check the sqlite table schema using the `.schemainfo` property. You can see that the 'pickle' datatype we chose above is represented as a BLOB column. This is because DocTable, using SQLAlchemy core, creates an interface on top of sqlite to handle the data conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DocTable::nssdocs ct: 0>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>nullable</th>\n",
       "      <th>default</th>\n",
       "      <th>autoincrement</th>\n",
       "      <th>primary_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>year</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>president</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>party</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>parsed</td>\n",
       "      <td>BLOB</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_paragraphs</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num_tokens</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name     type  nullable default autoincrement  primary_key\n",
       "0              id  INTEGER     False    None          auto            1\n",
       "1            year  INTEGER     False    None          auto            0\n",
       "2       president  VARCHAR      True    None          auto            0\n",
       "3           party  VARCHAR      True    None          auto            0\n",
       "4            text  VARCHAR      True    None          auto            0\n",
       "5          parsed     BLOB      True    None          auto            0\n",
       "6  num_paragraphs  INTEGER      True    None          auto            0\n",
       "7      num_tokens  INTEGER      True    None          auto            0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the DocTable object itself shows how many entries there are\n",
    "db = NSSDocs()\n",
    "print(db)\n",
    "pd.DataFrame(db.schemainfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's download and store the text into the database. Each loop downloads a text document and inserts it into the doctable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added parsed text to 1987: <DocTable::nssdocs ct: 1>\n",
      "added parsed text to 1993: <DocTable::nssdocs ct: 2>\n",
      "added parsed text to 2002: <DocTable::nssdocs ct: 3>\n",
      "added parsed text to 2015: <DocTable::nssdocs ct: 4>\n",
      "added parsed text to 1994: <DocTable::nssdocs ct: 5>\n",
      "added parsed text to 1990: <DocTable::nssdocs ct: 6>\n",
      "added parsed text to 1991: <DocTable::nssdocs ct: 7>\n",
      "added parsed text to 2006: <DocTable::nssdocs ct: 8>\n",
      "added parsed text to 1997: <DocTable::nssdocs ct: 9>\n",
      "added parsed text to 1995: <DocTable::nssdocs ct: 10>\n",
      "added parsed text to 1988: <DocTable::nssdocs ct: 11>\n",
      "added parsed text to 2017: <DocTable::nssdocs ct: 12>\n",
      "added parsed text to 1996: <DocTable::nssdocs ct: 13>\n",
      "added parsed text to 2010: <DocTable::nssdocs ct: 14>\n",
      "added parsed text to 1999: <DocTable::nssdocs ct: 15>\n",
      "added parsed text to 1998: <DocTable::nssdocs ct: 16>\n",
      "added parsed text to 2000: <DocTable::nssdocs ct: 17>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DocTable::nssdocs ct: 17>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for year, docmeta in nss_metadata.items():\n",
    "    text = download_nss(year)\n",
    "    db.insert({\n",
    "        'year':year, \n",
    "        'party': docmeta['party'], \n",
    "        'president': docmeta['president'],\n",
    "        'text': text, \n",
    "    }, ifnotunique='replace')\n",
    "    print(f'added parsed text to {year}: {db}')\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>president</th>\n",
       "      <th>party</th>\n",
       "      <th>text</th>\n",
       "      <th>parsed</th>\n",
       "      <th>num_paragraphs</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Reagan</td>\n",
       "      <td>R</td>\n",
       "      <td>I. An American Perspective \\n\\nIn the early da...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1993</td>\n",
       "      <td>H.W. Bush</td>\n",
       "      <td>R</td>\n",
       "      <td>Preface \\n\\nAmerican Leadership for Peaceful C...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  year  president party  \\\n",
       "0   1  1987     Reagan     R   \n",
       "1   2  1993  H.W. Bush     R   \n",
       "\n",
       "                                                text parsed num_paragraphs  \\\n",
       "0  I. An American Perspective \\n\\nIn the early da...   None           None   \n",
       "1  Preface \\n\\nAmerican Leadership for Peaceful C...   None           None   \n",
       "\n",
       "  num_tokens  \n",
       "0       None  \n",
       "1       None  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use select_df to show a couple rows of our database\n",
    "db.select_df(limit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we've filled the text column, but now we need to convert the text data into tokens in python.\n",
    "\n",
    "\n",
    "## Parse Text in the DocTable\n",
    "Now that the text is in the doctable, we can parse the text by reading from the table and store the parsed text there as well.\n",
    "\n",
    "#### Create a Parser Class Using a Pipeline\n",
    "Now we create a small `NSSParser` class that keeps a `doctable.ParsePipeline` for doing the actual text processing. Instantiating the package will load a spacy module into memory and construct the pipeline from the selected components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<spacy.lang.en.English at 0x7ff1a72e3048>,\n",
       " <function doctable.pipeline.component.<locals>.<lambda>(x)>,\n",
       " <function doctable.pipeline.component.<locals>.<lambda>(x)>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NSSParser(doctable.DocParser):\n",
    "    ''' Handles text parsing for NSS documents.'''\n",
    "    def __init__(self):\n",
    "        nlp = spacy.load('en')\n",
    "        \n",
    "        # this determines all settings for tokenizing\n",
    "        self.pipeline = doctable.ParsePipeline([\n",
    "            nlp, # first run spacy parser\n",
    "            doctable.component('merge_tok_spans', merge_ents=True),\n",
    "            doctable.component('tokenize', **{\n",
    "                'split_sents': False,\n",
    "                'keep_tok_func': doctable.component('keep_tok'),\n",
    "                'parse_tok_func': doctable.component('parse_tok', **{\n",
    "                    'format_ents': True,\n",
    "                    'num_replacement': 'NUM',\n",
    "                })\n",
    "            })\n",
    "        ])\n",
    "        \n",
    "    def parse(self, text):\n",
    "        return self.pipeline.parse(text)\n",
    "    \n",
    "    def parsemany(self, texts, workers=1):\n",
    "        return self.pipeline.parsemany(texts, workers=workers)\n",
    "\n",
    "parser = NSSParser() # creates a parser instance\n",
    "parser.pipeline.components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next block we loop through rows in the doctable and for each iteration parse the text document and insert it back into the table. Because each paragraph is independent, we can use our `.parsemany` method (simple wrapper over pipeline) to parse them all in parallel. To parse in parallel, you must specify a value for `workers` greater than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:14<00:00,  1.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DocTable::nssdocs ct: 17>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, year, text in tqdm(db.select(['id','year','text'])):\n",
    "    parsed = parser.parsemany(text.split('\\n\\n'), workers=30) # parse paragraphs in parallel\n",
    "    db.update({'parsed': parsed}, where=db['id']==idx)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>president</th>\n",
       "      <th>party</th>\n",
       "      <th>text</th>\n",
       "      <th>parsed</th>\n",
       "      <th>num_paragraphs</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Reagan</td>\n",
       "      <td>R</td>\n",
       "      <td>I. An American Perspective \\n\\nIn the early da...</td>\n",
       "      <td>[[I. An American, perspective], [in, The Early...</td>\n",
       "      <td>265</td>\n",
       "      <td>25302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1993</td>\n",
       "      <td>H.W. Bush</td>\n",
       "      <td>R</td>\n",
       "      <td>Preface \\n\\nAmerican Leadership for Peaceful C...</td>\n",
       "      <td>[[preface], [American, leadership, for, peacef...</td>\n",
       "      <td>125</td>\n",
       "      <td>13082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>W. Bush</td>\n",
       "      <td>R</td>\n",
       "      <td>The great struggles of the twentieth century b...</td>\n",
       "      <td>[[the, great, struggles, of, The Twentieth Cen...</td>\n",
       "      <td>199</td>\n",
       "      <td>13883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  year  president party  \\\n",
       "0   1  1987     Reagan     R   \n",
       "1   2  1993  H.W. Bush     R   \n",
       "2   3  2002    W. Bush     R   \n",
       "\n",
       "                                                text  \\\n",
       "0  I. An American Perspective \\n\\nIn the early da...   \n",
       "1  Preface \\n\\nAmerican Leadership for Peaceful C...   \n",
       "2  The great struggles of the twentieth century b...   \n",
       "\n",
       "                                              parsed  num_paragraphs  \\\n",
       "0  [[I. An American, perspective], [in, The Early...             265   \n",
       "1  [[preface], [American, leadership, for, peacef...             125   \n",
       "2  [[the, great, struggles, of, The Twentieth Cen...             199   \n",
       "\n",
       "   num_tokens  \n",
       "0       25302  \n",
       "1       13082  \n",
       "2       13883  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.select_df(limit=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see above that the `num_paragraphs` and `num_tokens` columns have been updated because of our custom `update` function in the `NSSDocs` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. NSS In Paragraph Form\n",
    "Our second example will look very similar, but this time we will create a doctable where each paragraph is a separate row in the database. We will use the same `Tokenize` class defined earlier, but update the doctable columns and slightly change our insert and parsing code. I aim to demonstrate here a general formula for processing large ammounts of text from a doctable for storage back into the doctable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DocTable::nss_paragraphs ct: 0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NSSParagraphs(doctable.DocTable):\n",
    "    tabname = 'nss_paragraphs'\n",
    "    schema = (\n",
    "        ('idcol', 'id'),\n",
    "        ('integer', 'year', dict(nullable=False)),\n",
    "        ('string','president'),\n",
    "        ('string','party'), ('check_constraint', 'party in (\"R\",\"D\")'),\n",
    "        ('integer', 'parnum', dict(nullable=False)), # added number to indicate which paragraph within the document\n",
    "        ('string', 'text'),\n",
    "        ('pickle','parsed'),\n",
    "        ('integer', 'num_tokens'),\n",
    "        ('index', 'ind_yr_parnum', ['year', 'parnum'], dict(unique=True)),\n",
    "    )\n",
    "    def __init__(self, fname=':memory:', **kwargs):\n",
    "        super().__init__(fname=fname, schema=self.schema, tabname=self.tabname, **kwargs)\n",
    "        \n",
    "    def update(self, row, **kwargs):\n",
    "        ''' Override insert to automatically calculate num_paragraphs and num_tokens.\n",
    "        '''\n",
    "        if 'parsed' in row:\n",
    "            row['num_tokens'] = len(row['parsed'])\n",
    "        return super().update(row, **kwargs) # call the regular doctable insert now.\n",
    "pdb = NSSParagraphs()\n",
    "pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:04<00:00,  4.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DocTable::nss_paragraphs ct: 5200>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for year, docmeta in tqdm(nss_metadata.items()):\n",
    "    partexts = download_nss(year).split('\\n\\n')\n",
    "    for i, text in enumerate(partexts):\n",
    "        pdb.insert({\n",
    "            'year':year, \n",
    "            'party': docmeta['party'], \n",
    "            'president': docmeta['president'],\n",
    "            'parnum': i,\n",
    "            'text': text, \n",
    "        }, ifnotunique='replace')\n",
    "pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>president</th>\n",
       "      <th>party</th>\n",
       "      <th>parnum</th>\n",
       "      <th>text</th>\n",
       "      <th>parsed</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Reagan</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>I. An American Perspective</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1987</td>\n",
       "      <td>Reagan</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>In the early days of this Administration we la...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1987</td>\n",
       "      <td>Reagan</td>\n",
       "      <td>R</td>\n",
       "      <td>2</td>\n",
       "      <td>Over the intervening years, we have looked obj...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1987</td>\n",
       "      <td>Reagan</td>\n",
       "      <td>R</td>\n",
       "      <td>3</td>\n",
       "      <td>Commitment to the goals of world freedom, peac...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1987</td>\n",
       "      <td>Reagan</td>\n",
       "      <td>R</td>\n",
       "      <td>4</td>\n",
       "      <td>While the United States has been the leader of...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  year president party  parnum  \\\n",
       "0   1  1987    Reagan     R       0   \n",
       "1   2  1987    Reagan     R       1   \n",
       "2   3  1987    Reagan     R       2   \n",
       "3   4  1987    Reagan     R       3   \n",
       "4   5  1987    Reagan     R       4   \n",
       "\n",
       "                                                text parsed num_tokens  \n",
       "0                        I. An American Perspective    None       None  \n",
       "1  In the early days of this Administration we la...   None       None  \n",
       "2  Over the intervening years, we have looked obj...   None       None  \n",
       "3  Commitment to the goals of world freedom, peac...   None       None  \n",
       "4  While the United States has been the leader of...   None       None  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse in Chunks\n",
    "A common approach to parsing involves processing chunks of texts in parallel. Using the parser shown in the previous example, I'll show how to use the `.select_chunks()` function to select chunks of rows at a time for parallel processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:14,  2.00s/it]\n"
     ]
    }
   ],
   "source": [
    "for rowchunk in tqdm(pdb.select_chunks(['id', 'text'], chunksize=1000)):\n",
    "    parsed = parser.parsemany([r['text'] for r in rowchunk], workers=30)\n",
    "    for row, p in zip(rowchunk, parsed):\n",
    "        pdb.update({'parsed': p}, where=pdb['id']==row['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>president</th>\n",
       "      <th>party</th>\n",
       "      <th>parnum</th>\n",
       "      <th>text</th>\n",
       "      <th>parsed</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Reagan</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>I. An American Perspective</td>\n",
       "      <td>[I. An American, perspective]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1987</td>\n",
       "      <td>Reagan</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>In the early days of this Administration we la...</td>\n",
       "      <td>[in, The Early Days, of, this, administration,...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1987</td>\n",
       "      <td>Reagan</td>\n",
       "      <td>R</td>\n",
       "      <td>2</td>\n",
       "      <td>Over the intervening years, we have looked obj...</td>\n",
       "      <td>[over, The Intervening Years, ,, we, have, loo...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1987</td>\n",
       "      <td>Reagan</td>\n",
       "      <td>R</td>\n",
       "      <td>3</td>\n",
       "      <td>Commitment to the goals of world freedom, peac...</td>\n",
       "      <td>[commitment, to, the, goals, of, world, freedo...</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1987</td>\n",
       "      <td>Reagan</td>\n",
       "      <td>R</td>\n",
       "      <td>4</td>\n",
       "      <td>While the United States has been the leader of...</td>\n",
       "      <td>[while, The United States, has, been, the, lea...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  year president party  parnum  \\\n",
       "0   1  1987    Reagan     R       0   \n",
       "1   2  1987    Reagan     R       1   \n",
       "2   3  1987    Reagan     R       2   \n",
       "3   4  1987    Reagan     R       3   \n",
       "4   5  1987    Reagan     R       4   \n",
       "\n",
       "                                                text  \\\n",
       "0                        I. An American Perspective    \n",
       "1  In the early days of this Administration we la...   \n",
       "2  Over the intervening years, we have looked obj...   \n",
       "3  Commitment to the goals of world freedom, peac...   \n",
       "4  While the United States has been the leader of...   \n",
       "\n",
       "                                              parsed  num_tokens  \n",
       "0                      [I. An American, perspective]           2  \n",
       "1  [in, The Early Days, of, this, administration,...          32  \n",
       "2  [over, The Intervening Years, ,, we, have, loo...          67  \n",
       "3  [commitment, to, the, goals, of, world, freedo...         167  \n",
       "4  [while, The United States, has, been, the, lea...          45  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All paragraphs have been parsed and inserted back into the database now. Using .`select_chunks` prevents us from loading too many text documents into memory at once, and using the `.parsemany` pipeline function (wrapped here by our custom `.parsemany` function) allows us to parse documents in parallel. The `chunksize` parameter can be adjusted according to available machine memory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
