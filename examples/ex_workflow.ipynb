{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Workflow Example\n",
    "This example shows a full example of a doctable workflow designed to parse texts end-to-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import doctable as dt\n",
    "import spacy\n",
    "from pprint import pprint\n",
    "import urllib.request # used for downloading nss docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Parser Class\n",
    "This class will be used to parse your entire corpus. It inherits from DocParser to use a number of built-in features to make parsing convenient. For maximum efficiency, it works by providing only a number of years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NSSDocs(dt.DocTable):\n",
    "    tabname = 'nssdocs'\n",
    "    schema = (\n",
    "        ('integer', 'id', dict(primary_key=True, autoincrement=True)),\n",
    "        ('integer', 'year', dict(unique=True)),\n",
    "        ('integer','num_pars'),\n",
    "        ('integer','num_sents'),\n",
    "        ('integer', 'num_toks'),\n",
    "        ('pickle','par_sents'), # nested tokens within sentences within paragraphs\n",
    "        ('index', 'ind_yr', ['year'], dict(unique=True)),        \n",
    "    )\n",
    "    def __init__(self, **kwargs):\n",
    "        dt.DocTable.__init__(self, schema=self.schema, tabname=self.tabname, **kwargs)\n",
    "        \n",
    "    def insert_nssdoc(self, year, par_sents, **kwargs):\n",
    "        self.insert({\n",
    "            'year': year,\n",
    "            'num_pars': len(par_sents),\n",
    "            'num_sents': len([s for par in par_sents for s in par]),\n",
    "            'num_toks': len([t for par in par_sents for s in par for t in s]),\n",
    "            'par_sents': par_sents,\n",
    "        }, **kwargs)\n",
    "\n",
    "class NSSParser(dt.DocParser):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.nlp = spacy.load('en')\n",
    "        \n",
    "    def parse_nss_docs(self, years, db, as_parsetree=False, workers=None):\n",
    "        '''Parse and store nss docs into a doctable.\n",
    "        Args:\n",
    "            years (list): years to request from the nss corpus\n",
    "        '''\n",
    "        self.distribute_chunks(self.parse_nss_chunk, years, self.nlp, db, as_parsetree, workers=workers)\n",
    "    \n",
    "    @classmethod\n",
    "    def parse_nss_chunk(cls, years, nlp, db, as_parsetree):\n",
    "        '''Run in separate process for each chunk of nss years.'''\n",
    "        # download, preprocess, and break texts into paragraphs\n",
    "        preprocess = lambda text: cls.preprocess(text, replace_xml='')\n",
    "        texts = list(map(preprocess, list(map(cls.download_nss, years))))\n",
    "        pars = [(i,par.strip()) for i,text in enumerate(texts) \n",
    "                      for par in text.split('\\n\\n') if len(par.strip()) > 0]\n",
    "        ind, pars = list(zip(*pars))\n",
    "        \n",
    "        use_tok = lambda tok: cls.use_tok(tok, filter_whitespace=True)\n",
    "        parse_tok = lambda tok: cls.parse_tok(tok, replace_num=True, format_ents=True)\n",
    "        \n",
    "        # choose to create either token sequences or parsetrees\n",
    "        if not as_parsetree:\n",
    "            tokenize = lambda doc: cls.tokenize_doc(doc, merge_ents=True, split_sents=True, parse_tok_func=parse_tok, use_tok_func=use_tok)\n",
    "        else:\n",
    "            tokenize = lambda doc: cls.get_parsetrees(doc, merge_ents=True, parse_tok_func=parse_tok)\n",
    "        \n",
    "        # process documents\n",
    "        pp = list()\n",
    "        for doc in nlp.pipe(pars):\n",
    "            toks = tokenize(doc)\n",
    "            pp.append(toks)\n",
    "            \n",
    "        # merge paragraphs back into docs and insert into db\n",
    "        doc_pars = [[p for idx,p in zip(ind,pp) if idx==i] for i in range(max(ind)+1)]\n",
    "        for yr,dp in zip(years,doc_pars):\n",
    "            db.insert_nssdoc(yr, dp, ifnotunique='replace')\n",
    "\n",
    "            \n",
    "    @staticmethod\n",
    "    def download_nss(year):\n",
    "        baseurl = 'https://raw.githubusercontent.com/devincornell/nssdocs/master/docs/{}.txt'\n",
    "        url = baseurl.format(year)\n",
    "        text = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>num_pars</th>\n",
       "      <th>num_sents</th>\n",
       "      <th>num_toks</th>\n",
       "      <th>par_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2015</td>\n",
       "      <td>150</td>\n",
       "      <td>659</td>\n",
       "      <td>16108</td>\n",
       "      <td>[[(ParseNode(Today), ParseNode(,), ParseNode(T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2017</td>\n",
       "      <td>400</td>\n",
       "      <td>1170</td>\n",
       "      <td>23625</td>\n",
       "      <td>[[(ParseNode(an), ParseNode(America), ParseNod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  year  num_pars  num_sents  num_toks  \\\n",
       "0  21  2015       150        659     16108   \n",
       "1  22  2017       400       1170     23625   \n",
       "\n",
       "                                           par_sents  \n",
       "0  [[(ParseNode(Today), ParseNode(,), ParseNode(T...  \n",
       "1  [[(ParseNode(an), ParseNode(America), ParseNod...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = (1987, 1988, 1990, 1991, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2002, 2006, 2010, 2015, 2017)\n",
    "parser = NSSParser()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>num_pars</th>\n",
       "      <th>num_sents</th>\n",
       "      <th>num_toks</th>\n",
       "      <th>par_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2002</td>\n",
       "      <td>199</td>\n",
       "      <td>652</td>\n",
       "      <td>13917</td>\n",
       "      <td>[[(ParseNode(the), ParseNode(great), ParseNode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1993</td>\n",
       "      <td>125</td>\n",
       "      <td>578</td>\n",
       "      <td>13134</td>\n",
       "      <td>[[(ParseNode(preface))], [(ParseNode(American)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  year  num_pars  num_sents  num_toks  \\\n",
       "0  23  2002       199        652     13917   \n",
       "1  24  1993       125        578     13134   \n",
       "\n",
       "                                           par_sents  \n",
       "0  [[(ParseNode(the), ParseNode(great), ParseNode...  \n",
       "1  [[(ParseNode(preface))], [(ParseNode(American)...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = NSSDocs(fname='exdb/ex_workflow_tokens.db')\n",
    "parser.parse_nss_docs(years, db, as_parsetree=False)\n",
    "print(db)\n",
    "db.select_df(limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = NSSDocs(fname='exdb/ex_workflow_parsetrees.db')\n",
    "parser.parse_nss_docs(years, db, as_parsetree=True)\n",
    "print(db)\n",
    "db.select_df(limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
