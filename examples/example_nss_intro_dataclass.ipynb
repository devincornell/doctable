{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Example 1: US National Security Strategy Document Corpus\n",
    "In this example, I'll show how to create a database for document + metadata storage using the `DocTable` class, and a parser class using a `ParsePipeline`. We will store the metadata you see below with the raw text and parsed tokens in the same DocTable."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import doctable\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "from pprint import pprint\n",
    "import urllib.request # used for downloading nss docs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction to NSS Corpus\n",
    "This dataset is the plain text version of the US National Security Strategy documents. During the parsing process, all plain text files will be downloaded from my [github project hosting the nss docs](https://github.com/devincornell/nssdocs). I compiled the metadata you see below from [a page hosted by the historical dept of the secretary's office](https://history.defense.gov/Historical-Sources/National-Security-Strategy/). In short, each US President must release at least one NSS per term, with some (namely Clinton) producing more.\n",
    "\n",
    "Here I've created the function `download_nss` to download the text data from my nssdocs github repository, and the python dictionary `nss_metadata` to store information about each document to be stored in the database."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def download_nss(year):\n",
    "    ''' Simple helper function for downloading texts from my nssdocs repo.'''\n",
    "    baseurl = 'https://raw.githubusercontent.com/devincornell/nssdocs/master/docs/{}.txt'\n",
    "    url = baseurl.format(year)\n",
    "    text = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "    return text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "nss_metadata = {\n",
    "    1987: {'party': 'R', 'president': 'Reagan'}, \n",
    "    1993: {'party': 'R', 'president': 'H.W. Bush'}, \n",
    "    2002: {'party': 'R', 'president': 'W. Bush'}, \n",
    "    2015: {'party': 'D', 'president': 'Obama'}, \n",
    "    1994: {'party': 'D', 'president': 'Clinton'}, \n",
    "    1990: {'party': 'R', 'president': 'H.W. Bush'}, \n",
    "    1991: {'party': 'R', 'president': 'H.W. Bush'}, \n",
    "    2006: {'party': 'R', 'president': 'W. Bush'}, \n",
    "    1997: {'party': 'D', 'president': 'Clinton'}, \n",
    "    1995: {'party': 'D', 'president': 'Clinton'}, \n",
    "    1988: {'party': 'R', 'president': 'Reagan'}, \n",
    "    2017: {'party': 'R', 'president': 'Trump'}, \n",
    "    1996: {'party': 'D', 'president': 'Clinton'}, \n",
    "    2010: {'party': 'D', 'president': 'Obama'}, \n",
    "    1999: {'party': 'D', 'president': 'Clinton'}, \n",
    "    1998: {'party': 'D', 'president': 'Clinton'}, \n",
    "    2000: {'party': 'D', 'president': 'Clinton'}\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# downloader example: first 100 characters of 1993 NSS document\n",
    "text = download_nss(1993)\n",
    "text[:100]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Preface \\n\\nAmerican Leadership for Peaceful Change \\n\\nOur great Nation stands at a crossroads in histo'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Create a DocTable Schema\n",
    "The `DocTable` class is often used by subclassing. Our `NSSDocs` class inherits from `DocTable` and will store connection and schema information. Because the default constructor checks for statically define member variables `tabname` and `schema` (as well as others), we can simply add them to the class definition. \n",
    "\n",
    "In this example, we create the 'id' column as a unique index, the 'year', 'president', and 'party' columns for storing the metadata we defined above in `nss_metadata`, and columns for raw and parse text. See the [schema guide](examples/doctable_schema.html) for examples of the full range of column types."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "\n",
    "@doctable.schema(require_slots=False)\n",
    "class NSSDoc:\n",
    "    id: int = doctable.IDCol()\n",
    "    year: int = doctable.Col(nullable=False)\n",
    "    president: str = doctable.Col()\n",
    "    party: str = doctable.Col()\n",
    "    text: str = doctable.Col()\n",
    "    parsed: Any = doctable.Col()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can then create a connection to a database by instantiating the `NSSDocs` class. Since the `fname` parameter was not provided, this doctable exists only in memory using sqlite (uses special sqlite name \":memory:\"). We will use this for these examples.\n",
    "\n",
    "We can check the sqlite table schema using `.schema_table()`. You can see that the 'pickle' datatype we chose above is represented as a BLOB column. This is because DocTable, using SQLAlchemy core, creates an interface on top of sqlite to handle the data conversion. You can view the number of documents using `.count()` or by viewing the db instance as a string (in this case with print function)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# printing the DocTable object itself shows how many entries there are\n",
    "db = doctable.DocTable(schema=NSSDoc, target=':memory:', verbose=True)\n",
    "print(db.count())\n",
    "print(db)\n",
    "db.schema_table()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DocTable: SELECT count() AS count_1 \n",
      "FROM _documents_\n",
      " LIMIT ? OFFSET ?\n",
      "0\n",
      "<DocTable (6 cols)::sqlite:///:memory::_documents_>\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        name     type  nullable default autoincrement  primary_key\n",
       "0         id  INTEGER     False    None          auto            1\n",
       "1       year  INTEGER     False    None          auto            0\n",
       "2  president  VARCHAR      True    None          auto            0\n",
       "3      party  VARCHAR      True    None          auto            0\n",
       "4       text  VARCHAR      True    None          auto            0\n",
       "5     parsed     BLOB      True    None          auto            0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>nullable</th>\n",
       "      <th>default</th>\n",
       "      <th>autoincrement</th>\n",
       "      <th>primary_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>year</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>president</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>party</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text</td>\n",
       "      <td>VARCHAR</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>parsed</td>\n",
       "      <td>BLOB</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Insert Data Into the Table"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's download and store the text into the database. Each loop downloads a text document and inserts it into the doctable, and we use the `.insert()` method to insert a single row at a time. The row to be inserted is represented as a dictionary, and any missing column information is left as NULL. The `ifnotunique` argument is set to false because if we were to re-run this code, it needs to replace the existing document of the same year. Recall that in the schema we placed a unique constraint on the year column."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "for year, docmeta in tqdm(nss_metadata.items()):\n",
    "    text = download_nss(year)\n",
    "    new_doc = NSSDoc(\n",
    "        year=year, \n",
    "        party=docmeta['party'], \n",
    "        president=docmeta['president'], \n",
    "        text=text\n",
    "    )\n",
    "    db.insert(new_doc, ifnotunique='replace', verbose=False)\n",
    "db.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 17/17 [00:01<00:00, 12.31it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DocTable: SELECT _documents_.id, _documents_.year, _documents_.president, _documents_.party, _documents_.text, _documents_.parsed \n",
      "FROM _documents_\n",
      " LIMIT ? OFFSET ?\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  year  president party  \\\n",
       "0   1  1987     Reagan     R   \n",
       "1   2  1993  H.W. Bush     R   \n",
       "2   3  2002    W. Bush     R   \n",
       "3   4  2015      Obama     D   \n",
       "4   5  1994    Clinton     D   \n",
       "\n",
       "                                                text  \\\n",
       "0  I. An American Perspective \\n\\nIn the early da...   \n",
       "1  Preface \\n\\nAmerican Leadership for Peaceful C...   \n",
       "2  The great struggles of the twentieth century b...   \n",
       "3  Today, the United States is stronger and bette...   \n",
       "4  Preface \\n\\nProtecting our nation's security -...   \n",
       "\n",
       "                                              parsed  \n",
       "0  [[I., An, American, Perspective], [in, the, ea...  \n",
       "1  [[preface], [American, leadership, for, peacef...  \n",
       "2  [[the, great, struggles, of, the, twentieth, c...  \n",
       "3  [[Today, ,, the, United, States, is, stronger,...  \n",
       "4  [[preface], [protecting, our, nation, 's, secu...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>president</th>\n",
       "      <th>party</th>\n",
       "      <th>text</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Reagan</td>\n",
       "      <td>R</td>\n",
       "      <td>I. An American Perspective \\n\\nIn the early da...</td>\n",
       "      <td>[[I., An, American, Perspective], [in, the, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1993</td>\n",
       "      <td>H.W. Bush</td>\n",
       "      <td>R</td>\n",
       "      <td>Preface \\n\\nAmerican Leadership for Peaceful C...</td>\n",
       "      <td>[[preface], [American, leadership, for, peacef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>W. Bush</td>\n",
       "      <td>R</td>\n",
       "      <td>The great struggles of the twentieth century b...</td>\n",
       "      <td>[[the, great, struggles, of, the, twentieth, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>Obama</td>\n",
       "      <td>D</td>\n",
       "      <td>Today, the United States is stronger and bette...</td>\n",
       "      <td>[[Today, ,, the, United, States, is, stronger,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1994</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>D</td>\n",
       "      <td>Preface \\n\\nProtecting our nation's security -...</td>\n",
       "      <td>[[preface], [protecting, our, nation, 's, secu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Query Table Data\n",
    "Now that we have inserted the NSS documents into the table, there are a few ways we can query the data. To select the first entry of the table use `.select_first()`. This method returns a simple `sqlalchemy.RowProxy` object which can be accessed like a dictionary or like a tuple."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "row = db.select_first()\n",
    "#print(row)\n",
    "print(row['president'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DocTable: SELECT _documents_.id, _documents_.year, _documents_.president, _documents_.party, _documents_.text, _documents_.parsed \n",
      "FROM _documents_\n",
      " LIMIT ? OFFSET ?\n",
      "Reagan\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To select more than one row, use the `.select()` method. If you'd only like to return the first few rows, you can use the `limit` argument."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "rows = db.select(limit=2)\n",
    "print(rows[0]['year'])\n",
    "print(rows[1]['year'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DocTable: SELECT _documents_.id, _documents_.year, _documents_.president, _documents_.party, _documents_.text, _documents_.parsed \n",
      "FROM _documents_\n",
      " LIMIT ? OFFSET ?\n",
      "1987\n",
      "1993\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also select only a few columns."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "db.select(['year', 'president'], limit=3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DocTable: SELECT _documents_.year, _documents_.president \n",
      "FROM _documents_\n",
      " LIMIT ? OFFSET ?\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[NSSDoc(year=1987, president='Reagan'),\n",
       " NSSDoc(year=1993, president='H.W. Bush'),\n",
       " NSSDoc(year=2002, president='W. Bush')]"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For convenience, we can also use the `.select_df()` method to return directly as a pandas dataframe."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# use select_df to show a couple rows of our database\n",
    "db.select_df(limit=2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DocTable: SELECT _documents_.id, _documents_.year, _documents_.president, _documents_.party, _documents_.text, _documents_.parsed \n",
      "FROM _documents_\n",
      " LIMIT ? OFFSET ?\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  year  president party  \\\n",
       "0   1  1987     Reagan     R   \n",
       "1   2  1993  H.W. Bush     R   \n",
       "\n",
       "                                                text  \\\n",
       "0  I. An American Perspective \\n\\nIn the early da...   \n",
       "1  Preface \\n\\nAmerican Leadership for Peaceful C...   \n",
       "\n",
       "                                              parsed  \n",
       "0  [[I., An, American, Perspective], [in, the, ea...  \n",
       "1  [[preface], [American, leadership, for, peacef...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>president</th>\n",
       "      <th>party</th>\n",
       "      <th>text</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Reagan</td>\n",
       "      <td>R</td>\n",
       "      <td>I. An American Perspective \\n\\nIn the early da...</td>\n",
       "      <td>[[I., An, American, Perspective], [in, the, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1993</td>\n",
       "      <td>H.W. Bush</td>\n",
       "      <td>R</td>\n",
       "      <td>Preface \\n\\nAmerican Leadership for Peaceful C...</td>\n",
       "      <td>[[preface], [American, leadership, for, peacef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Create a Parser for Tokenization\n",
    "Now that the text is in the doctable, we can extract it using `.select()`, parse it, and store the parsed text back into the table using `.update()`.\n",
    "\n",
    "Now we create a parser using `ParsePipeline` and a list of functions to apply to the text sequentially. The `Comp` function returns a [doctable parse function](ref/doctable.parse.html) with additional keyword arguments. For instance, the following two expressions would be the same.\n",
    "```\n",
    "doctable.component('keep_tok', keep_punct=True) # is equivalent to\n",
    "lambda x: doctable.parse.parse_tok_func(x, keep_punct=True)\n",
    "```\n",
    "Note in this example that the 'tokenize' function takes two function arguments `keep_tok_func` and `parse_tok_func` which are also specified using the `.Comp()` function. The available pipeline components are listed in the [parse function documentation](ref/doctable.parse.html)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# first load a spacy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# add pipeline components\n",
    "parser = doctable.ParsePipeline([\n",
    "    nlp, # first run spacy parser\n",
    "    doctable.Comp('tokenize', **{\n",
    "        'split_sents': False,\n",
    "        'keep_tok_func': doctable.Comp('keep_tok'),\n",
    "        'parse_tok_func': doctable.Comp('parse_tok'),\n",
    "    })\n",
    "])\n",
    "\n",
    "parser.components"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<spacy.lang.en.English at 0x7f2cd9334400>,\n",
       " functools.partial(<function tokenize at 0x7f2d86167160>, split_sents=False, keep_tok_func=functools.partial(<function keep_tok at 0x7f2d86167280>), parse_tok_func=functools.partial(<function parse_tok at 0x7f2d861671f0>))]"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we loop through rows in the doctable and for each iteration parse the text and insert it back into the table using `.update()`. We use the `ParsePipeline` method `.parsemany()` to parse paragraphs from each document in parallel. This is much faster."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "docs = db.select()\n",
    "for doc in tqdm(docs):\n",
    "    doc.parsed = parser.parsemany(doc.text[:1000].split('\\n\\n'), workers=8) # parse paragraphs in parallel\n",
    "    db.update_dataclass(doc, verbose=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/51 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DocTable: SELECT _documents_.id, _documents_.year, _documents_.president, _documents_.party, _documents_.text, _documents_.parsed \n",
      "FROM _documents_\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 51/51 [00:04<00:00, 11.42it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "See the 'parsed' column in the dataframe below to view the paragraphs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "db.select_df(limit=3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DocTable: SELECT _documents_.id, _documents_.year, _documents_.president, _documents_.party, _documents_.text, _documents_.parsed \n",
      "FROM _documents_\n",
      " LIMIT ? OFFSET ?\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  year  president party  \\\n",
       "0   1  1987     Reagan     R   \n",
       "1   2  1993  H.W. Bush     R   \n",
       "2   3  2002    W. Bush     R   \n",
       "\n",
       "                                                text  \\\n",
       "0  I. An American Perspective \\n\\nIn the early da...   \n",
       "1  Preface \\n\\nAmerican Leadership for Peaceful C...   \n",
       "2  The great struggles of the twentieth century b...   \n",
       "\n",
       "                                              parsed  \n",
       "0  [[I., An, American, Perspective], [in, the, ea...  \n",
       "1  [[preface], [American, leadership, for, peacef...  \n",
       "2  [[the, great, struggles, of, the, twentieth, c...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>president</th>\n",
       "      <th>party</th>\n",
       "      <th>text</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Reagan</td>\n",
       "      <td>R</td>\n",
       "      <td>I. An American Perspective \\n\\nIn the early da...</td>\n",
       "      <td>[[I., An, American, Perspective], [in, the, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1993</td>\n",
       "      <td>H.W. Bush</td>\n",
       "      <td>R</td>\n",
       "      <td>Preface \\n\\nAmerican Leadership for Peaceful C...</td>\n",
       "      <td>[[preface], [American, leadership, for, peacef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>W. Bush</td>\n",
       "      <td>R</td>\n",
       "      <td>The great struggles of the twentieth century b...</td>\n",
       "      <td>[[the, great, struggles, of, the, twentieth, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "And here we show a few tokenized paragraphs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "paragraphs = db.select_first('parsed')\n",
    "for par in paragraphs[:3]:\n",
    "    print(par, '\\n')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DocTable: SELECT _documents_.parsed \n",
      "FROM _documents_\n",
      " LIMIT ? OFFSET ?\n",
      "['I.', 'An', 'American', 'Perspective'] \n",
      "\n",
      "['in', 'the', 'early', 'days', 'of', 'this', 'administration', 'we', 'laid', 'the', 'foundation', 'for', 'a', 'more', 'constructive', 'and', 'positive', 'American', 'role', 'in', 'world', 'affairs', 'by', 'clarifying', 'the', 'essential', 'elements', 'of', 'U.S.', 'foreign', 'and', 'defense', 'policy', '.'] \n",
      "\n",
      "['over', 'the', 'intervening', 'years', ',', 'we', 'have', 'looked', 'objectively', 'at', 'our', 'policies', 'and', 'performance', 'on', 'the', 'world', 'scene', 'to', 'ensure', 'they', 'reflect', 'the', 'dynamics', 'of', 'a', 'complex', 'and', 'ever', '-', 'changing', 'world', '.', 'where', 'course', 'adjustments', 'have', 'been', 'required', ',', 'i', 'have', 'directed', 'changes', '.', 'but', 'we', 'have', 'not', 'veered', 'and', 'will', 'not', 'veer', 'from', 'the', 'broad', 'aims', 'that', 'guide', 'America', \"'s\", 'leadership', 'role', 'in', 'today', \"'s\", 'world', ':'] \n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "80712910726593b564a07c7ac6087ce3072c1b43af7fa58c28aea85a2c346dd3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}