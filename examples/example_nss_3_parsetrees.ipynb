{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: NSS Corpus in Paragraph Form\n",
    "Here I'll show how to make a DocTable for storing NSS documents at the paragraph level, and parse the documents in parallel.\n",
    "\n",
    "For context, check out [Example 1](https://devincornell.github.io/doctable/examples/ex_nss.html) - here we'll just use some shortcuts for code used there. These come from the util.py code in the repo examples folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import util\n",
    "import doctable\n",
    "import spacy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we get the data as a list of dictionaries. We'll skip the details of downloading the nss data just to use for illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['party', 'president', 'text', 'year'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nss_data = util.download_all_nssdata()\n",
    "print(nss_data[0].keys())\n",
    "len(nss_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Add Data to a DocTable\n",
    "We now proceed to make a doctable and add our data to it. We made our schema match the format from the data retrieved above, so only need to use the `.insert` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NSSParsetrees(doctable.DocTable):\n",
    "    tabname = 'nss_parsetrees'\n",
    "    schema = (\n",
    "        ('idcol', 'id'),\n",
    "        ('integer', 'year'), \n",
    "        ('string', 'party'),\n",
    "        ('string', 'president'),\n",
    "        ('string', 'text'),\n",
    "        ('pickle', 'parsetrees'),\n",
    "    )\n",
    "    def __init__(self, fname=':memory:', **kwargs):\n",
    "        super().__init__(fname=fname, schema=self.schema, tabname=self.tabname, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DocTable::nss_parsetrees ct: 17>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>party</th>\n",
       "      <th>president</th>\n",
       "      <th>text</th>\n",
       "      <th>parsetrees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>R</td>\n",
       "      <td>Reagan</td>\n",
       "      <td>I. An American Perspective \\n\\nIn the early da...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1988</td>\n",
       "      <td>R</td>\n",
       "      <td>Reagan</td>\n",
       "      <td>Preface\\n\\nThis statement of America's Nationa...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  year party president  \\\n",
       "0   1  1987     R    Reagan   \n",
       "1   2  1988     R    Reagan   \n",
       "\n",
       "                                                text parsetrees  \n",
       "0  I. An American Perspective \\n\\nIn the early da...       None  \n",
       "1  Preface\\n\\nThis statement of America's Nationa...       None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add docs to database\n",
    "db = NSSParsetrees()\n",
    "for nssdoc in nss_data:\n",
    "    db.insert(nssdoc)\n",
    "print(db)\n",
    "db.select_df(limit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a Parser Class Using a Pipeline\n",
    "Now we create a small `NSSParser` class that keeps a `doctable.ParsePipeline` object for doing the actual text processing. As you can see from our init method, instantiating the package will load a spacy module into memory and construct the pipeline from the selected components. We also create a wrapper over the pipeline `.parse` and `.parsemany` methods. Here we define, instantiate, and view the components of `NSSParser`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<spacy.lang.en.English at 0x7fdb4ca5cc50>,\n",
       " <function doctable.pipeline.component.<locals>.<lambda>(x)>,\n",
       " <function doctable.pipeline.component.<locals>.<lambda>(x)>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NSSParser:\n",
    "    ''' Handles text parsing for NSS documents.'''\n",
    "    def __init__(self):\n",
    "        nlp = spacy.load('en')\n",
    "        \n",
    "        # this determines all settings for tokenizing\n",
    "        self.pipeline = doctable.ParsePipeline([\n",
    "            nlp, # first run spacy parser\n",
    "            doctable.component('merge_tok_spans', merge_ents=True),\n",
    "            doctable.component('get_parsetrees', **{\n",
    "                'parse_tok_func': doctable.component('parse_tok', **{\n",
    "                    'format_ents': True,\n",
    "                    'num_replacement': 'NUM',\n",
    "                })\n",
    "            })\n",
    "        ])\n",
    "    \n",
    "    def parsemany(self, texts, workers=1):\n",
    "        return self.pipeline.parsemany(texts, workers=workers)\n",
    "\n",
    "parser = NSSParser() # creates a parser instance\n",
    "parser.pipeline.components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:21<00:00,  1.27s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>party</th>\n",
       "      <th>president</th>\n",
       "      <th>text</th>\n",
       "      <th>parsetrees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>R</td>\n",
       "      <td>Reagan</td>\n",
       "      <td>I. An American Perspective \\n\\nIn the early da...</td>\n",
       "      <td>[(ParseNode(I. An American), ParseNode(perspec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1988</td>\n",
       "      <td>R</td>\n",
       "      <td>Reagan</td>\n",
       "      <td>Preface\\n\\nThis statement of America's Nationa...</td>\n",
       "      <td>[(ParseNode(preface)), (ParseNode(this), Parse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  year party president  \\\n",
       "0   1  1987     R    Reagan   \n",
       "1   2  1988     R    Reagan   \n",
       "\n",
       "                                                text  \\\n",
       "0  I. An American Perspective \\n\\nIn the early da...   \n",
       "1  Preface\\n\\nThis statement of America's Nationa...   \n",
       "\n",
       "                                          parsetrees  \n",
       "0  [(ParseNode(I. An American), ParseNode(perspec...  \n",
       "1  [(ParseNode(preface)), (ParseNode(this), Parse...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, year, text in tqdm(db.select(['id','year','text'])):\n",
    "    parsed = parser.parsemany(text.split('\\n\\n'), workers=30) # parse paragraphs in parallel\n",
    "    parsetrees = [pt for par in parsed for pt in par]\n",
    "    db.update({'parsetrees': parsetrees}, where=db['id']==idx)\n",
    "db.select_df(limit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Work With Parsetrees\n",
    "Above you can see that we have loaded all the parsetrees from our sample. Now we show an example illustrating how you would extract simple subject-verb-object triplets from sentences in the NSS documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I. An American perspective\n",
      "\n",
      "\n",
      "in The Early Days of this administration we laid the foundation for a more constructive and positive American role in world affairs by clarifying the essential elements of U.S. foreign and defense policy .\n",
      "we laid foundation\n",
      "None clarifying elements\n",
      "\n",
      "\n",
      "over The Intervening Years , we have looked objectively at our policies and performance on the world scene to ensure they reflect the dynamics of a complex and ever - changing world .\n",
      "we looked None\n",
      "None ensure None\n",
      "they reflect dynamics\n",
      "None changing None\n",
      "\n",
      "\n",
      "where course adjustments have been required , i have directed changes .\n",
      "None required None\n",
      "i directed changes\n",
      "\n",
      "\n",
      "but we have not veered and will not veer from the broad aims that guide America 's leadership role in Today 's world :\n",
      "we veered None\n",
      "None will None\n",
      "None veer None\n",
      "that guide role\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def first_pos(tok, pos):\n",
    "    for child in tok.childs:\n",
    "        if child.dep == pos:\n",
    "            return child.text\n",
    "        \n",
    "for i,pt in enumerate(db.select_first('parsetrees')):\n",
    "    print(' '.join([p.text for p in pt])) # print out sentence\n",
    "    for tok in pt:\n",
    "        if tok.pos == 'VERB':\n",
    "            print(first_pos(tok, 'nsubj'), tok.text, first_pos(tok, 'dobj'))\n",
    "            \n",
    "    print('\\n')\n",
    "    if i == 4:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
